# -*- coding: utf-8 -*-
"""V5mnist(sucess).ipynb

Automatically generated by Colab.



### Importing Packages and Libraries
"""

!pip install datasets transformers huggingface_hub evaluate albumentations
!apt-get install git-lfs

"""### Importing libraries"""

import numpy as np
import pandas as pd
import torch
import cv2
import albumentations as A
from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer
from datasets import load_dataset
import evaluate
import tensorflow as tf

def set_seed(seed: int = int):
    random.seed(seed)                  # Python random module
    np.random.seed(seed)                # Numpy
    torch.manual_seed(seed)             # PyTorch
    torch.cuda.manual_seed_all(seed)    # GPU-based randomness
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(100) # creating a function that on all the libraries it'll ensure replicability across different environments such as python, numpy, pytorch and gpu

### setting random seed for replicability across all environments

seed = 100
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
tf.random.set_seed(seed)

mnist_data = {'Label': [0,1,2,3,4,5,6,7,8,9], 'Description': ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']}
pd.DataFrame(mnist_data)
# this shows the encoded label of each item of clothing inside of the Datatset. can be found https://www.kaggle.com/datasets/zalando-research/fashionmnist/data

mnist = load_dataset("zalando-datasets/fashion_mnist")
# loading the dataset from HuggingFace instead of doing the steps of converting it from a csv to a format hugging face accepts

from sklearn.model_selection import train_test_split
if "validation" not in mnist:
  splits = mnist["train"].train_test_split(test_size=0.3, seed=seed)
  mnist["train"] = splits["train"]
  mnist["validation"] = splits["test"]

# this creates a validation dataset to prevent overfitting overfitting allowing the model tuning by providing an unbiased evaluation of performance during training

mnist
# this provides an overview of the newly formed dataset with a validation

# from evaluate import load_metric
# metric = load_metric("accuracy")

train_dataset = mnist['train']
val_dataset = mnist['validation']
test_dataset = mnist['test']
# assigning variables that would be useful to be called upon later

print(f"Number of training images: {len(train_dataset)}")
print(f"Number of test images: {len(test_dataset)}")
print(f"Number of validation images: {len(val_dataset)}")

# this just shows the how many images are in each dataset

mnist['train'].features

mnist["train"].features["label"]

index = mnist['train'][0]
resized_image = cv2.resize(np.array(index['image']), (200, 200))
resized_image
# showing the images

labels = mnist["train"].features["label"].names
label2id, id2label = {}, {}
for i, label in enumerate(labels):
    label2id[label] = i
    id2label[i] = label

print(id2label[0])

# this code decodes intergers back into strings to see what the classification of the image is on the training dataset

model_checkpoint = "abhishek/autotrain_fashion_mnist_vit_base"
image_processor = AutoImageProcessor.from_pretrained(model_checkpoint, num_channels =1)
image_processor
# this preprocesses the images ready for the images to be transformin either through resizing, normalizing, mean and standard deviation.
# finding this model through Hugging Face, Image Classification and fashion mnist

if "height" in image_processor.size:
    size = (image_processor.size["height"], image_processor.size["width"])
    crop_size = size
    max_size = None
elif "height" in image_processor.size:
    size = (image_processor.size[224], image_processor.size[224])
    crop_size = size
    max_size = None

train_transforms = A.Compose([
    A.Resize(height=224, width=224),
    A.RandomRotate90(),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.Normalize(),
])

val_transforms = A.Compose([
    A.Resize(height=224, width=224),
    A.Normalize(),
])



def preprocess_train(examples):
    examples["pixel_values"] = [
        train_transforms(image=np.array(image))["image"] for image in examples["image"]
    ]
    return examples

def preprocess_val(examples):
    examples["pixel_values"] = [
        val_transforms(image=np.array(image))["image"] for image in examples["image"]
    ]
    return examples

# here we have two different functions for the training dataset and then the validation dataset that augments the dataset though
# rotation, resising, flipping, brightness and nomalising for the training then resizing thn normalising for the vlidation set

seed = 100
np.random.seed(seed)
#tf.random.set_seed(seed)

# this is redundant, ignore as its higher up in the .py

# splits = mnist['train'].train_test_split(test_size=0.3, seed= seed)
# train_sts = splits['train']
# val_sts = splits['test']
# this is also higher up on the .py file

train_dataset.set_transform(preprocess_train)
val_dataset.set_transform(preprocess_val)
# the application of the functions to the variables that. set_transform allows the aplication of the function

train_dataset[0]

num_labels = len(id2label)
model = AutoModelForImageClassification.from_pretrained(
    model_checkpoint,
    num_labels=num_labels,
    id2label=id2label,
    label2id=label2id,
)
# the ocde her downloads the pretrained model and allows it to be finetuned. the usa

model_name = model_checkpoint.split("/")[-1]
batch_size = 32
args = TrainingArguments(
    output_dir=f"{model_name}-finetuned-fashion-mnist",
    seed=seed,
    remove_unused_columns=False,
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=batch_size,
    gradient_accumulation_steps=4,
    per_device_eval_batch_size=batch_size,
    num_train_epochs=3,
    warmup_ratio=0.1,
    logging_steps=10,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    push_to_hub=False,
)

import evaluate

eval_metric = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    predictions = np.argmax(eval_pred.predictions, axis=1)
    return eval_metric.compute(predictions=predictions, references=eval_pred.label_ids)

import torch

import cv2

def collate_fn(examples):
    images = []
    labels = []
    for example in examples:
        image = np.array(example["pixel_values"])

        # Ensure grayscale (H, W) or (H, W, 1) -> RGB (H, W, 3)
        if len(image.shape) == 2 or (len(image.shape) == 3 and image.shape[2] == 1):
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

        # Convert (H, W, 3) -> (3, H, W) for PyTorch
        image = np.moveaxis(image, source=2, destination=0)
        images.append(torch.from_numpy(image))
        labels.append(example["label"])

    pixel_values = torch.stack(images)
    labels = torch.tensor(labels)
    return {"pixel_values": pixel_values, "labels": labels}

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    processing_class=image_processor,
    compute_metrics=compute_metrics,
    data_collator=collate_fn,
)

trainer.train()

metrics = trainer.evaluate()
print(metrics)

